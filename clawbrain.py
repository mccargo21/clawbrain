#!/usr/bin/env python3
"""
Brain v3 - Personal AI Memory System with SQLite Support

Features:
- ðŸŽ­ Soul/Personality - Evolving traits
- ðŸ‘¤ User Profile - Learns preferences
- ðŸ’­ Conversation State - Mood/intent detection
- ðŸ“š Learning Insights - Continuous improvement
- ðŸ§  get_full_context() - Everything for personalized responses

Supports: SQLite (default), PostgreSQL, Redis
"""

import os
import json
import hashlib
import sqlite3
from datetime import datetime
from typing import Optional, List, Dict, Any
from dataclasses import dataclass, field, asdict
from pathlib import Path
from contextlib import contextmanager
from threading import Lock
import logging

logger = logging.getLogger(__name__)

# Optional dependencies
EMBEDDINGS_AVAILABLE = False
try:
    from sentence_transformers import SentenceTransformer
    EMBEDDINGS_AVAILABLE = True
except ImportError:
    pass

POSTGRES_AVAILABLE = False
try:
    import psycopg2
    import psycopg2.extras
    POSTGRES_AVAILABLE = True
except ImportError:
    pass

REDIS_AVAILABLE = False
try:
    import redis
    REDIS_AVAILABLE = True
except ImportError:
    pass


@dataclass
class Memory:
    id: str
    agent_id: str
    memory_type: str
    key: str
    content: str
    content_encrypted: bool
    summary: str
    keywords: List[str]
    importance: int
    linked_to: str
    source: str
    embedding: List[float]
    created_at: str
    updated_at: str


@dataclass
class UserProfile:
    user_id: str
    name: Optional[str] = None
    nickname: Optional[str] = None
    preferred_name: Optional[str] = None
    communication_preferences: Dict[str, Any] = field(default_factory=dict)
    interests: List[str] = field(default_factory=list)
    expertise_areas: List[str] = field(default_factory=list)
    learning_topics: List[str] = field(default_factory=list)
    timezone: Optional[str] = None
    active_hours: Dict[str, Any] = field(default_factory=dict)
    conversation_patterns: Dict[str, Any] = field(default_factory=dict)
    emotional_patterns: Dict[str, Any] = field(default_factory=dict)
    important_dates: Dict[str, Any] = field(default_factory=dict)
    life_context: Dict[str, Any] = field(default_factory=dict)
    total_interactions: int = 0
    first_interaction: Optional[str] = None
    last_interaction: Optional[str] = None
    updated_at: Optional[str] = None


DEFAULT_CONFIG = {
    "storage_backend": "auto",  # "sqlite", "postgresql", "auto"
    "sqlite_path": "./brain_data.db",
    "postgres_host": "192.168.4.176",
    "postgres_port": 5432,
    "postgres_db": "brain_db",
    "postgres_user": "brain_user",
    "postgres_password": "brain_secure_password_2024_rotated",
    "redis_host": "192.168.4.175",
    "redis_port": 6379,
    "redis_db": 0,
    "redis_prefix": "brain:",
    "embedding_model": "all-MiniLM-L6-v2",
    "backup_dir": "./brain_backups",
}


class Brain:
    def __init__(self, config: Dict = None):
        self.config = {**DEFAULT_CONFIG, **(config or {})}
        self._lock = Lock()
        self._storage = None
        self._redis = None
        self._pg_conn = None
        self._embedder = Embedder(self.config["embedding_model"]) if EMBEDDINGS_AVAILABLE else None
        
        # Determine storage backend
        storage = self.config.get("storage_backend", "auto")
        
        if storage == "auto":
            if POSTGRES_AVAILABLE and self._try_postgres():
                self._setup_postgres()
                self._storage = "postgresql"
            else:
                self._setup_sqlite()
                self._storage = "sqlite"
        elif storage == "sqlite":
            self._setup_sqlite()
            self._storage = "sqlite"
        elif storage == "postgresql" and POSTGRES_AVAILABLE:
            self._setup_postgres()
            self._storage = "postgresql"
        else:
            self._setup_sqlite()
            self._storage = "sqlite"
        
        if REDIS_AVAILABLE and self.config.get("use_redis", True):
            self._setup_redis()
        
        self._backup_dir = Path(self.config["backup_dir"])
        self._backup_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"Brain initialized with {self._storage} storage")
    
    def _try_postgres(self) -> bool:
        if not POSTGRES_AVAILABLE:
            return False
        try:
            conn = psycopg2.connect(
                host=self.config["postgres_host"],
                port=self.config["postgres_port"],
                database=self.config["postgres_db"],
                user=self.config["postgres_user"],
                password=self.config["postgres_password"],
                connect_timeout=3
            )
            conn.close()
            return True
        except Exception as e:
            logger.warning(f"PostgreSQL not available: {e}")
            return False
    
    def _setup_sqlite(self):
        db_path = Path(self.config["sqlite_path"])
        db_path.parent.mkdir(parents=True, exist_ok=True)
        self._sqlite_path = str(db_path)
        self._sqlite_conn = sqlite3.connect(self._sqlite_path, check_same_thread=False)
        self._sqlite_conn.row_factory = sqlite3.Row
        self._create_sqlite_tables()
        logger.info(f"SQLite initialized at {self._sqlite_path}")
    
    def _create_sqlite_tables(self):
        cursor = self._sqlite_conn.cursor()
        
        tables = [
            """CREATE TABLE IF NOT EXISTS conversations (
                id TEXT PRIMARY KEY, agent_id TEXT, session_key TEXT, messages TEXT,
                summary TEXT, keywords TEXT, embedding TEXT, created_at TEXT, updated_at TEXT)""",
            """CREATE TABLE IF NOT EXISTS memories (
                id TEXT PRIMARY KEY, agent_id TEXT, memory_type TEXT, key TEXT, content TEXT,
                content_encrypted INTEGER, summary TEXT, keywords TEXT, importance INTEGER,
                linked_to TEXT, source TEXT, embedding TEXT, created_at TEXT, updated_at TEXT)""",
            """CREATE TABLE IF NOT EXISTS todos (
                id TEXT PRIMARY KEY, agent_id TEXT, title TEXT, description TEXT,
                status TEXT, priority INTEGER, due_date TEXT, created_at TEXT, updated_at TEXT)""",
            """CREATE TABLE IF NOT EXISTS souls (
                agent_id TEXT PRIMARY KEY, traits TEXT, preferred_topics TEXT,
                interaction_count INTEGER, created_at TEXT, updated_at TEXT)""",
            """CREATE TABLE IF NOT EXISTS bonds (
                user_id TEXT PRIMARY KEY, level REAL, score INTEGER, total_interactions INTEGER,
                first_interaction TEXT, last_interaction TEXT, milestones TEXT,
                created_at TEXT, updated_at TEXT)""",
            """CREATE TABLE IF NOT EXISTS goals (
                id TEXT PRIMARY KEY, agent_id TEXT, title TEXT, description TEXT,
                status TEXT, progress INTEGER, milestones TEXT, created_at TEXT, updated_at TEXT)""",
            """CREATE TABLE IF NOT EXISTS user_profiles (
                user_id TEXT PRIMARY KEY, name TEXT, nickname TEXT, preferred_name TEXT,
                communication_preferences TEXT, interests TEXT, expertise_areas TEXT,
                learning_topics TEXT, timezone TEXT, active_hours TEXT, conversation_patterns TEXT,
                emotional_patterns TEXT, important_dates TEXT, life_context TEXT,
                total_interactions INTEGER, first_interaction TEXT, last_interaction TEXT, updated_at TEXT)""",
            """CREATE TABLE IF NOT EXISTS learning_insights (
                id TEXT PRIMARY KEY, insight_type TEXT, content TEXT, confidence REAL,
                source_context TEXT, times_reinforced INTEGER, times_contradicted INTEGER,
                is_active INTEGER, created_at TEXT, last_reinforced TEXT)""",
            """CREATE TABLE IF NOT EXISTS topic_clusters (
                id TEXT PRIMARY KEY, name TEXT, related_terms TEXT, parent_topic TEXT,
                child_topics TEXT, embedding TEXT, usage_count INTEGER,
                last_discussed TEXT, created_at TEXT)""",
        ]
        
        for sql in tables:
            cursor.execute(sql)
        self._sqlite_conn.commit()
    
    def _setup_postgres(self):
        self._pg_conn = psycopg2.connect(
            host=self.config["postgres_host"],
            port=self.config["postgres_port"],
            database=self.config["postgres_db"],
            user=self.config["postgres_user"],
            password=self.config["postgres_password"]
        )
        self._pg_conn.autocommit = True
    
    def _setup_redis(self):
        if not REDIS_AVAILABLE:
            return
        try:
            self._redis = redis.Redis(
                host=self.config["redis_host"],
                port=self.config["redis_port"],
                db=self.config.get("redis_db", 0),
                decode_responses=True,
                socket_timeout=3,
                socket_connect_timeout=3
            )
            self._redis.ping()
            self._redis_prefix = self.config.get("redis_prefix", "brain:")
            logger.info("Redis connected for caching")
        except Exception as e:
            logger.warning(f"Redis not available: {e}")
            self._redis = None
    
    @property
    def storage_backend(self) -> str:
        return self._storage
    
    # ========== MEMORIES ==========
    def remember(self, agent_id: str, memory_type: str, content: str, key: str = None, **kwargs) -> Memory:
        now = datetime.now().isoformat()
        memory_id = str(hashlib.md5(f"{agent_id}:{memory_type}:{content[:100]}".encode()).hexdigest())
        keywords = self._extract_keywords([{"content": content}])
        embedding = None
        if self._embedder and self._embedder.model and memory_type != "secret":
            embedding = self._embedder.embed(content)
        
        memory = Memory(
            id=memory_id, agent_id=agent_id, memory_type=memory_type,
            key=key or f"{memory_type}:{content[:50]}",
            content=content, content_encrypted=False,
            summary=self._summarize([{"content": content}]),
            keywords=keywords, importance=kwargs.get("importance", 5),
            linked_to=kwargs.get("linked_to"), source=kwargs.get("source"),
            embedding=embedding, created_at=now, updated_at=now
        )
        
        with self._get_cursor() as cursor:
            if self._storage == "sqlite":
                cursor.execute("""INSERT OR IGNORE INTO memories 
                    (id, agent_id, memory_type, key, content, content_encrypted, summary, keywords, 
                     importance, linked_to, source, embedding, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (memory.id, memory.agent_id, memory.memory_type, memory.key, memory.content,
                     int(memory.content_encrypted), memory.summary, json.dumps(memory.keywords),
                     memory.importance, memory.linked_to, memory.source,
                     json.dumps(memory.embedding) if memory.embedding else None,
                     memory.created_at, memory.updated_at))
            else:
                cursor.execute("""INSERT INTO memories 
                    (id, agent_id, memory_type, key, content, content_encrypted, summary, keywords,
                     importance, linked_to, source, embedding, created_at, updated_at)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (id) DO NOTHING""",
                    (memory.id, memory.agent_id, memory.memory_type, memory.key, memory.content,
                     memory.content_encrypted, memory.summary, memory.keywords,
                     memory.importance, memory.linked_to, memory.source,
                     psycopg2.extras.Json(memory.embedding) if memory.embedding else None,
                     memory.created_at, memory.updated_at))
        return memory
    
    def recall(self, agent_id: str = None, query: str = None, memory_type: str = None, limit: int = 10) -> List[Memory]:
        with self._get_cursor() as cursor:
            conditions, params = [], []
            if agent_id:
                conditions.append("agent_id = " + ("?" if self._storage == "sqlite" else "%s"))
                params.append(agent_id)
            if memory_type:
                conditions.append("memory_type = " + ("?" if self._storage == "sqlite" else "%s"))
                params.append(memory_type)
            where = " AND ".join(conditions) if conditions else "1=1"
            limit_param = limit
            
            if self._storage == "sqlite":
                cursor.execute(f"SELECT * FROM memories WHERE {where} ORDER BY importance DESC, created_at DESC LIMIT {limit_param}", tuple(params))
            else:
                if params:
                    cursor.execute(f"SELECT * FROM memories WHERE {where} ORDER BY importance DESC, created_at DESC LIMIT %s", tuple(params + [limit]))
                else:
                    cursor.execute(f"SELECT * FROM memories WHERE {where} ORDER BY importance DESC, created_at DESC LIMIT %s", (limit,))
            
            rows = cursor.fetchall()
        return [self._row_to_memory(row) for row in rows]
    
    def _row_to_memory(self, row) -> Memory:
        # Handle keywords - can be list (PostgreSQL) or string (SQLite)
        keywords = row["keywords"]
        if isinstance(keywords, str):
            keywords = json.loads(keywords) if keywords else []
        
        # Handle embedding - can be list (PostgreSQL JSON) or string (SQLite)
        embedding = row["embedding"]
        if isinstance(embedding, str):
            embedding = json.loads(embedding) if embedding else None
        
        return Memory(
            id=row["id"], agent_id=row["agent_id"], memory_type=row["memory_type"],
            key=row["key"], content=row["content"], content_encrypted=bool(row["content_encrypted"]),
            summary=row["summary"], keywords=keywords,
            importance=row["importance"], linked_to=row["linked_to"], source=row["source"],
            embedding=embedding,
            created_at=row["created_at"], updated_at=row["updated_at"]
        )
    
    # ========== CONVERSATIONS ==========
    def remember_conversation(self, session_key: str, messages: List[Dict], agent_id: str = "jarvis", summary: str = None) -> str:
        now = datetime.now().isoformat()
        conv_id = str(hashlib.md5(f"{session_key}:{now}".encode()).hexdigest())
        keywords = self._extract_keywords(messages)
        
        with self._get_cursor() as cursor:
            if self._storage == "sqlite":
                cursor.execute("""INSERT OR REPLACE INTO conversations 
                    (id, agent_id, session_key, messages, summary, keywords, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)""",
                    (conv_id, agent_id, session_key, json.dumps(messages), summary,
                     json.dumps(keywords), now, now))
            else:
                cursor.execute("""INSERT INTO conversations 
                    (id, agent_id, session_key, messages, summary, keywords, created_at, updated_at)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (id) DO UPDATE SET messages = conversations.messages || EXCLUDED.messages""",
                    (conv_id, agent_id, session_key, json.dumps(messages), summary,
                     json.dumps(keywords), now, now))
        return conv_id
    
    def get_conversation(self, session_key: str, limit: int = None) -> List[Dict]:
        if self._redis:
            cached = self._redis.get(f"{self._redis_prefix}conv:{session_key}")
            if cached:
                data = json.loads(cached)
                return data.get("messages", [])[-limit:] if limit else data.get("messages", [])
        
        with self._get_cursor() as cursor:
            if self._storage == "sqlite":
                cursor.execute("SELECT messages FROM conversations WHERE session_key = ? ORDER BY created_at DESC LIMIT 1", (session_key,))
            else:
                cursor.execute("SELECT messages FROM conversations WHERE session_key = %s ORDER BY created_at DESC LIMIT 1", (session_key,))
            row = cursor.fetchone()
        
        if row:
            messages = row["messages"] if self._storage == "sqlite" else (row["messages"] or [])
            if self._redis:
                cache_data = json.dumps({"messages": messages})
                self._redis.setex(f"{self._redis_prefix}conv:{session_key}", 3600, cache_data)
            return messages[-limit:] if limit else messages
        return []
    
    # ========== USER PROFILES ==========
    def get_user_profile(self, user_id: str) -> UserProfile:
        with self._get_cursor() as cursor:
            if self._storage == "sqlite":
                cursor.execute("SELECT * FROM user_profiles WHERE user_id = ?", (user_id,))
            else:
                cursor.execute("SELECT * FROM user_profiles WHERE user_id = %s", (user_id,))
            row = cursor.fetchone()
        
        if row:
            # Helper to parse JSON fields that might be dict/list already (PostgreSQL) or string (SQLite)
            def parse_json(val, default):
                if val is None:
                    return default
                if isinstance(val, str):
                    return json.loads(val) if val else default
                return val
            
            return UserProfile(
                user_id=row["user_id"], name=row["name"], nickname=row["nickname"],
                preferred_name=row["preferred_name"],
                communication_preferences=parse_json(row["communication_preferences"], {}),
                interests=parse_json(row["interests"], []),
                expertise_areas=parse_json(row["expertise_areas"], []),
                learning_topics=parse_json(row["learning_topics"], []),
                timezone=row["timezone"],
                active_hours=parse_json(row["active_hours"], {}),
                conversation_patterns=parse_json(row["conversation_patterns"], {}),
                emotional_patterns=parse_json(row["emotional_patterns"], {}),
                important_dates=parse_json(row["important_dates"], {}),
                life_context=parse_json(row["life_context"], {}),
                total_interactions=row["total_interactions"] or 0,
                first_interaction=row["first_interaction"],
                last_interaction=row["last_interaction"],
                updated_at=row["updated_at"]
            )
        return UserProfile(user_id=user_id)
    
    def learn_user_preference(self, user_id: str, preference_type: str, value: str):
        profile = self.get_user_profile(user_id)
        now = datetime.now().isoformat()
        
        if profile.first_interaction is None:
            profile.first_interaction = now
        profile.last_interaction = now
        profile.total_interactions += 1
        profile.updated_at = now
        
        if preference_type == "interest" and value not in profile.interests:
            profile.interests.append(value)
        elif preference_type == "expertise" and value not in profile.expertise_areas:
            profile.expertise_areas.append(value)
        elif preference_type == "learning" and value not in profile.learning_topics:
            profile.learning_topics.append(value)
        
        with self._get_cursor() as cursor:
            if self._storage == "sqlite":
                cursor.execute("""INSERT OR REPLACE INTO user_profiles 
                    (user_id, name, nickname, preferred_name, communication_preferences, interests,
                     expertise_areas, learning_topics, timezone, active_hours, conversation_patterns,
                     emotional_patterns, important_dates, life_context, total_interactions,
                     first_interaction, last_interaction, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (profile.user_id, profile.name, profile.nickname, profile.preferred_name,
                     json.dumps(profile.communication_preferences), json.dumps(profile.interests),
                     json.dumps(profile.expertise_areas), json.dumps(profile.learning_topics),
                     profile.timezone, json.dumps(profile.active_hours),
                     json.dumps(profile.conversation_patterns), json.dumps(profile.emotional_patterns),
                     json.dumps(profile.important_dates), json.dumps(profile.life_context),
                     profile.total_interactions, profile.first_interaction, profile.last_interaction,
                     profile.updated_at))
            else:
                cursor.execute("""INSERT INTO user_profiles 
                    (user_id, name, nickname, preferred_name, communication_preferences, interests,
                     expertise_areas, learning_topics, timezone, active_hours, conversation_patterns,
                     emotional_patterns, important_dates, life_context, total_interactions,
                     first_interaction, last_interaction, updated_at)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (user_id) DO UPDATE SET
                        interests = EXCLUDED.interests,
                        total_interactions = user_profiles.total_interactions + 1,
                        last_interaction = EXCLUDED.last_interaction""",
                    (profile.user_id, profile.name, profile.nickname, profile.preferred_name,
                     psycopg2.extras.Json(profile.communication_preferences), profile.interests,
                     profile.expertise_areas, profile.learning_topics,
                     profile.timezone, psycopg2.extras.Json(profile.active_hours),
                     psycopg2.extras.Json(profile.conversation_patterns), psycopg2.extras.Json(profile.emotional_patterns),
                     psycopg2.extras.Json(profile.important_dates), psycopg2.extras.Json(profile.life_context),
                     profile.total_interactions, profile.first_interaction, profile.last_interaction,
                     profile.updated_at))
    
    # ========== MOOD/INTENT DETECTION ==========
    def detect_user_mood(self, message: str) -> Dict[str, Any]:
        message_lower = message.lower()
        mood_keywords = {
            "happy": ["great", "awesome", "love", "excellent", "happy", "wonderful", "amazing", "excited"],
            "frustrated": ["annoying", "hate", "stupid", "frustrated", "angry", "terrible", "worst"],
            "stressed": ["busy", "overwhelmed", "stressed", "anxious", "worry", "panic"],
            "curious": ["how", "why", "what", "tell me", "explain", "wondering", "interested"],
            "sad": ["unfortunately", "sad", "disappointed", "sorry", "unhappy"],
        }
        mood_scores = {}
        for mood, keywords in mood_keywords.items():
            matches = sum(1 for kw in keywords if kw in message_lower)
            if matches > 0:
                mood_scores[mood] = matches / len(keywords)
        
        if mood_scores:
            top_mood = max(mood_scores, key=mood_scores.get)
            return {"mood": top_mood, "confidence": min(0.9, 0.3 + mood_scores[top_mood] * 0.3), "all_moods": mood_scores}
        return {"mood": "neutral", "confidence": 0.5, "all_moods": {}}
    
    def detect_user_intent(self, message: str) -> str:
        message_lower = message.lower().strip()
        if any(greet in message_lower for greet in ["hello", "hi", "hey", "good morning"]):
            return "greeting"
        elif "?" in message or message_lower.startswith(("what", "how", "why", "can you", "could you")):
            return "question"
        elif any(req in message_lower for req in ["please", "can you", "i want", "i need"]):
            return "request"
        elif any(fb in message_lower for fb in ["actually", "no that's", "wrong"]):
            return "feedback"
        elif any(bye in message_lower for bye in ["bye", "goodbye", "later"]):
            return "farewell"
        return "statement"
    
    # ========== FULL CONTEXT ==========
    def get_full_context(self, session_key: str, user_id: str = "default", agent_id: str = "moltbot", message: str = None) -> Dict[str, Any]:
        now = datetime.now()
        message_analysis = {}
        if message:
            message_analysis = {"mood": self.detect_user_mood(message), "intent": self.detect_user_intent(message)}
        
        conversation_state = self.get_conversation(session_key)
        user_profile = self.get_user_profile(user_id)
        memories = self.recall(agent_id=agent_id, limit=10)
        
        return {
            "user": {
                "profile": {"name": user_profile.preferred_name or user_profile.name,
                           "interests": user_profile.interests, "expertise": user_profile.expertise_areas},
                "preferred_name": user_profile.preferred_name or user_profile.name,
                "interests": user_profile.interests,
                "communication_style": user_profile.communication_preferences,
            },
            "conversation": {
                "state": {"user_mood": message_analysis.get("mood", {}).get("mood", "neutral") if message_analysis else "neutral",
                         "intent": message_analysis.get("intent", "statement") if message_analysis else "statement"},
                "history": conversation_state,
                "turn_count": len(conversation_state) if conversation_state else 0,
                "current_topic": "",
            },
            "message_analysis": message_analysis,
            "memories": [asdict(m) for m in memories],
            "time_context": {"time_of_day": now.strftime("%H:%M"), "timestamp": now.isoformat()},
            "response_guidance": {
                "tone": "friendly", "formality": user_profile.communication_preferences.get("formality", "casual"),
                "verbosity": user_profile.communication_preferences.get("verbosity", "concise"),
                "use_humor": user_profile.communication_preferences.get("use_humor", True),
                "use_emoji": user_profile.communication_preferences.get("use_emoji", True),
                "show_empathy": False, "be_encouraging": True, "match_energy": False, "response_type": "conversational",
            },
        }
    
    def process_message(self, message: str, session_key: str, user_id: str = "default", agent_id: str = "moltbot") -> Dict[str, Any]:
        return self.get_full_context(session_key, user_id, agent_id, message)
    
    def generate_personality_prompt(self, agent_id: str = "moltbot", user_id: str = "default") -> str:
        profile = self.get_user_profile(user_id)
        prompt = f"You are {agent_id}, a personal AI assistant who is helpful and friendly."
        if profile.preferred_name:
            prompt += f" Your human is named {profile.preferred_name}."
        if profile.interests:
            prompt += f" They're interested in: {', '.join(profile.interests[:3])}."
        return prompt
    
    # ========== HELPER METHODS ==========
    def _extract_keywords(self, messages: List[Dict]) -> List[str]:
        keywords = []
        for msg in messages:
            content = msg.get("content", "").lower()
            words = [w for w in content.split() if len(w) > 3 and w not in ["that", "this", "with", "from", "have"]]
            keywords.extend(words[:5])
        return list(set(keywords))[:10]
    
    def _summarize(self, messages: List[Dict]) -> str:
        if not messages:
            return ""
        content = " ".join(m.get("content", "") for m in messages)
        return content[:100] + "..." if len(content) > 100 else content
    
    @contextmanager
    def _get_cursor(self):
        with self._lock:
            if self._storage == "sqlite":
                cursor = self._sqlite_conn.cursor()
                try:
                    yield cursor
                    self._sqlite_conn.commit()
                finally:
                    cursor.close()
            else:
                cursor = self._pg_conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
                try:
                    yield cursor
                finally:
                    cursor.close()
    
    def health_check(self) -> Dict[str, bool]:
        return {"storage": self._storage in ["sqlite", "postgresql"], "sqlite": self._storage == "sqlite",
                "postgres": self._storage == "postgresql", "redis": self._redis is not None,
                "backup_dir": self._backup_dir.exists()}
    
    def close(self):
        if hasattr(self, '_sqlite_conn') and self._sqlite_conn:
            self._sqlite_conn.close()
        if self._pg_conn:
            self._pg_conn.close()
        if self._redis:
            self._redis.close()


class Embedder:
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        self.model = None
        if EMBEDDINGS_AVAILABLE:
            try:
                self.model = SentenceTransformer(model_name)
            except Exception as e:
                logger.warning(f"Could not load embedding model: {e}")
    
    def embed(self, text: str) -> Optional[List[float]]:
        if self.model and text:
            try:
                return self.model.encode(text).tolist()
            except:
                return None
        return None
